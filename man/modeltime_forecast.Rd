% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/modeltime-forecast.R
\name{modeltime_forecast}
\alias{modeltime_forecast}
\title{Forecast future data}
\usage{
modeltime_forecast(
  object,
  new_data = NULL,
  h = NULL,
  actual_data = NULL,
  conf_interval = 0.95,
  conf_by_id = FALSE,
  conf_method = "conformal_default",
  keep_data = FALSE,
  arrange_index = FALSE,
  ...
)
}
\arguments{
\item{object}{A Modeltime Table}

\item{new_data}{A \code{tibble} containing future information to forecast.
If \code{NULL}, forecasts the calibration data.}

\item{h}{The forecast horizon (can be used instead of \code{new_data} for
time series with no exogenous regressors).
Extends the calibration data \code{h} periods into the future.}

\item{actual_data}{Reference data that is combined with the output tibble and given a \code{.key = "actual"}}

\item{conf_interval}{An estimated confidence interval based on the calibration data.
This is designed to estimate future confidence from \emph{out-of-sample prediction error}.}

\item{conf_by_id}{Whether or not to produce confidence interval estimates by an ID feature.
\itemize{
\item When \code{FALSE}, a global model confidence interval is provided.
\item If \code{TRUE}, a local confidence interval is provided group-wise for each time series ID.
To enable local confidence interval, an \code{id} must be provided during \code{modeltime_calibrate()}.
}}

\item{conf_method}{Algorithm used to produce confidence intervals. All CI's are Conformal Predictions. Choose one of:
\itemize{
\item \code{conformal_default}: Uses \code{qnorm()} to compute quantiles from out-of-sample (test set) residuals.
\item \code{conformal_split}: Uses the split method split conformal inference method described by Lei \emph{et al} (2018)
}}

\item{keep_data}{Whether or not to keep the \code{new_data} and \code{actual_data} as extra columns in the results.
This can be useful if there is an important feature in the \code{new_data} and \code{actual_data} needed
when forecasting.
Default: \code{FALSE}.}

\item{arrange_index}{Whether or not to sort the index in rowwise chronological order (oldest to newest) or to
keep the original order of the data.
Default: \code{FALSE}.}

\item{...}{Not currently used}
}
\value{
A tibble with predictions and time-stamp data. For ease of plotting and calculations,
the column names are transformed to:
\itemize{
\item \code{.key}: Values labeled either "prediction" or "actual"
\item \code{.index}: The timestamp index.
\item \code{.value}: The value being forecasted.
}

Additionally, if the Modeltime Table has been previously calibrated using \code{\link[=modeltime_calibrate]{modeltime_calibrate()}},
you will gain confidence intervals.
\itemize{
\item \code{.conf_lo}: The lower limit of the confidence interval.
\item \code{.conf_hi}: The upper limit of the confidence interval.
}

Additional descriptive columns are included:
\itemize{
\item \code{.model_id}: Model ID from the Modeltime Table
\item \code{.model_desc}: Model Description from the Modeltime Table
}

Unnecessary columns are \emph{dropped} to save space:
\itemize{
\item \code{.model}
\item \code{.calibration_data}
}
}
\description{
The goal of \code{modeltime_forecast()} is to simplify the process of
forecasting future data.
}
\details{
The \code{modeltime_forecast()} function prepares a forecast for visualization with
with \code{\link[=plot_modeltime_forecast]{plot_modeltime_forecast()}}. The forecast is controlled by \code{new_data} or \code{h},
which can be combined with existing data (controlled by \code{actual_data}).
Confidence intervals are included if the incoming Modeltime Table has been
calibrated using \code{\link[=modeltime_calibrate]{modeltime_calibrate()}}.
Otherwise confidence intervals are not estimated.

\strong{New Data}

When forecasting you can specify future data using \code{new_data}.
This is a future tibble with date column and columns for xregs
extending the trained dates and exogonous regressors (xregs) if used.
\itemize{
\item \strong{Forecasting Evaluation Data}: By default, the \code{new_data} will use the \code{.calibration_data}
if \code{new_data} is not provided.
This is the equivalent of using \code{rsample::testing()} for getting test data sets.
\item \strong{Forecasting Future Data}: See \code{timetk::future_frame()} for creating future tibbles.
\item \strong{Xregs}: Can be used with this method
}

\strong{H (Horizon)}

When forecasting, you can specify \code{h}. This is a phrase like "1 year",
which extends the \code{.calibration_data} (1st priority) or the \code{actual_data} (2nd priority)
into the future.
\itemize{
\item \strong{Forecasting Future Data}: All forecasts using \code{h} are
\emph{\strong{extended after the calibration data or actual_data}}.
\item Extending \code{.calibration_data} - Calibration data is given 1st priority, which is
desirable \emph{after refitting} with \code{\link[=modeltime_refit]{modeltime_refit()}}.
Internally, a call is made to \code{timetk::future_frame()} to
expedite creating new data using the date feature.
\item Extending \code{actual_data} - If \code{h} is provided, and the modeltime table has not been
calibrated, the "actual_data" will be extended into the future. This is useful
in situations where you want to go directly from \code{modeltime_table()} to \code{modeltime_forecast()}
without calibrating or refitting.
\item \strong{Xregs}: Cannot be used because future data must include new xregs.
If xregs are desired, build a future data frame and use \code{new_data}.
}

\strong{Actual Data}

This is reference data that contains the true values of the time-stamp data.
It helps in visualizing the performance of the forecast vs the actual data.

When \code{h} is used and the Modeltime Table has \emph{not been calibrated}, then the
actual data is extended into the future periods that are defined by \code{h}.

\strong{Confidence Interval Estimation}

Confidence intervals (\code{.conf_lo}, \code{.conf_hi}) are estimated based on the normal estimation of
the testing errors (out of sample) from \code{\link[=modeltime_calibrate]{modeltime_calibrate()}}.
The out-of-sample error estimates are then carried through and
applied to applied to any future forecasts.

The confidence interval can be adjusted with the \code{conf_interval} parameter. The algorithm used
to produce confidence intervals can be changed with the \code{conf_method} parameter.

\emph{Conformal Default Method:}

When \code{conf_method = "conformal_default"} (default), this method uses \code{qnorm()}
to produce a 95\% confidence interval by default. It estimates a normal (Gaussian distribution)
based on the out-of-sample errors (residuals).

The confidence interval is \emph{mean-adjusted}, meaning that if the mean of the residuals
is non-zero, the confidence interval is adjusted to widen the interval to capture
the difference in means.

\emph{Conformal Split Method:}

When \verb{conf_method = "conformal_split}, this method uses the split conformal inference method
described by Lei \emph{et al} (2018). This is also implemented in the \code{probably} R package's
\code{int_conformal_split()} function.

\emph{What happens to the confidence interval after refitting models?}

Refitting has no affect on the confidence interval since this is calculated independently of
the refitted model. New observations typically improve
future accuracy, which in most cases makes the out-of-sample confidence intervals conservative.

\strong{Keep Data}

Include the new data (and actual data) as extra columns with the results of the model forecasts.
This can be helpful when the new data includes information useful to the forecasts.
An example is when forecasting \emph{Panel Data} and the new data contains
ID features related to the time series group that the forecast belongs to.

\strong{Arrange Index}

By default, \code{modeltime_forecast()} keeps the original order of the data.
If desired, the user can sort the output by \code{.key}, \code{.model_id} and \code{.index}.
}
\examples{
library(dplyr)
library(timetk)
library(parsnip)
library(rsample)

# Data
m750 <- m4_monthly \%>\% filter(id == "M750")

# Split Data 80/20
splits <- initial_time_split(m750, prop = 0.9)

# --- MODELS ---

# Model 1: prophet ----
model_fit_prophet <- prophet_reg() \%>\%
    set_engine(engine = "prophet") \%>\%
    fit(value ~ date, data = training(splits))


# ---- MODELTIME TABLE ----

models_tbl <- modeltime_table(
    model_fit_prophet
)

# ---- CALIBRATE ----

calibration_tbl <- models_tbl \%>\%
    modeltime_calibrate(new_data = testing(splits))

# ---- ACCURACY ----

calibration_tbl \%>\%
    modeltime_accuracy()

# ---- FUTURE FORECAST ----

calibration_tbl \%>\%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = m750
    )

# ---- ALTERNATIVE: FORECAST WITHOUT CONFIDENCE INTERVALS ----
# Skips Calibration Step, No Confidence Intervals

models_tbl \%>\%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = m750
    )

# ---- KEEP NEW DATA WITH FORECAST ----
# Keeps the new data. Useful if new data has information
#  like ID features that should be kept with the forecast data

calibration_tbl \%>\%
    modeltime_forecast(
        new_data      = testing(splits),
        keep_data     = TRUE
    )

}
\references{
Lei, Jing, et al. "Distribution-free predictive inference for regression."
\emph{Journal of the American Statistical Association} 113.523 (2018): 1094-1111.
}
